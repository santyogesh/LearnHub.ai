{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Download and read csv file of transactions\n",
        "# Downloading csv file stored in drive folder\n",
        "# I am using open source data of transactions from Kaggle - 'https://www.kaggle.com/mlg-ulb/creditcardfraud'\n",
        "!pip install gdown --quiet\n",
        "\n",
        "import gdown\n",
        "import pandas as pd\n",
        "\n",
        "file_id = \"1tAJqSAySFdlcx-TiCUef43ErkFFU1r0G\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\" # getting file from a folder in drive\n",
        "\n",
        "# Download CSV file to setup local environment (the csv file path is later used in the modelling code)\n",
        "gdown.download(url, \"creditcard.csv\", quiet=False)\n",
        "\n",
        "# Load data and sample visualize\n",
        "df = pd.read_csv(\"creditcard.csv\")\n",
        "print(\"Dataset loaded:\", df.shape)\n",
        "df\n",
        "\n",
        "# About the dataset -\n",
        "\n",
        "# The dataset contains credit card transactions made by European cardholders\n",
        "# in September 2013. It covers a period of two days and includes a total of\n",
        "# 284,807 transactions, out of which 492 are fraudulent. This makes the dataset\n",
        "# highly imbalanced, as frauds represent only about 0.172% of all transactions.\n",
        "#\n",
        "# All the features are numerical. Most of them (V1, V2, … V28) come from a\n",
        "# Principal Component Analysis (PCA) transformation, since the original\n",
        "# features cannot be shared due to confidentiality. The only features not\n",
        "# transformed with PCA are ‘Time’ and ‘Amount’. ‘Time’ represents the seconds\n",
        "# elapsed between a transaction and the first transaction in the dataset,\n",
        "# while ‘Amount’ is the transaction value and can be useful in\n",
        "# cost-sensitive learning. The target variable is ‘Class’, where a value of 1\n",
        "# indicates fraud and 0 indicates a genuine transaction.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "collapsed": true,
        "id": "EoWUn2jsW-SM",
        "outputId": "daba2124-2136-4c5c-ebec-1d5430d7a758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1tAJqSAySFdlcx-TiCUef43ErkFFU1r0G\n",
            "From (redirected): https://drive.google.com/uc?id=1tAJqSAySFdlcx-TiCUef43ErkFFU1r0G&confirm=t&uuid=f6ea9e93-c769-4b85-9c7c-e03dd5c082ec\n",
            "To: /content/creditcard.csv\n",
            "100%|██████████| 151M/151M [00:01<00:00, 93.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: (284807, 31)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
              "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
              "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
              "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
              "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
              "...          ...        ...        ...       ...       ...       ...   \n",
              "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V21       V22  \\\n",
              "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
              "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
              "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
              "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
              "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
              "...          ...       ...       ...       ...  ...       ...       ...   \n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
              "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
              "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
              "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
              "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
              "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
              "...          ...       ...       ...       ...       ...       ...     ...   \n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
              "\n",
              "        Class  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "284802      0  \n",
              "284803      0  \n",
              "284804      0  \n",
              "284805      0  \n",
              "284806      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3158aa4a-68cf-4b23-8bca-9b042a90e419\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3158aa4a-68cf-4b23-8bca-9b042a90e419')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3158aa4a-68cf-4b23-8bca-9b042a90e419 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3158aa4a-68cf-4b23-8bca-9b042a90e419');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9fef83a0-36a5-45ef-aef2-df8737e39d11\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9fef83a0-36a5-45ef-aef2-df8737e39d11')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9fef83a0-36a5-45ef-aef2-df8737e39d11 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_cd94ab32-b54a-4af1-967c-aa69d42021c9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cd94ab32-b54a-4af1-967c-aa69d42021c9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model for predicting fraud transactrions using neural network\n",
        "# After downloading csv file from my drive to create local environment, I'll continue on with reading it\n",
        "import pandas as pd\n",
        "\n",
        "credit_card_data = pd.read_csv(\"/content/creditcard.csv\") # read csv file of transactions to get columns and data\n",
        "\n",
        "print(\"Shape of dataset:\", credit_card_data.shape)\n",
        "print(credit_card_data.head()) #see the columns\n",
        "\n",
        "# Dropping columns that don't really help in pattern learning:\n",
        "# 'Time' (just a sequence) and 'Amount' (fraud can happen with any amount).\n",
        "transaction_features =credit_card_data.drop(columns=[\"Time\",\"Amount\",\"Class\"])\n",
        "fraud_labels = credit_card_data[\"Class\"]\n",
        "\n",
        "print(\"Number of features used:\", transaction_features.shape[1]) # check if undesired columns are dropped\n",
        "print(\"Class distribution (0=Normal,1=Fraud):\")\n",
        "print(fraud_labels.value_counts())\n",
        "\n",
        "# Normalizing the inputs for stability and unbiased treatment of features, larger values might lead to bias towards some features\n",
        "from sklearn.preprocessing import StandardScaler #[https://scikit-learn.org/stable/modules/preprocessing.html]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_transaction_features = scaler.fit_transform(transaction_features)\n",
        "\n",
        "print(\"Example of a scaled feature row:\")\n",
        "print(scaled_transaction_features[0][:10])   # printing first 10 values of row 0\n",
        "\n",
        "# Splitiing data into test and train [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html]\n",
        "from sklearn.model_selection import  train_test_split\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(\n",
        "    scaled_transaction_features,\n",
        "    fraud_labels,\n",
        "    test_size=0.25, # 25% test set for good measure\n",
        "    random_state=2025,\n",
        "    stratify=fraud_labels # stratify keeps fraud ratio same in both sets for better learning\n",
        ")\n",
        "\n",
        "print(\"Training set size:\",train_features.shape)\n",
        "print(\"Testing set size:\", test_features.shape)\n",
        "\n",
        "# Setting up neural network by specifying input layer size, number of neurons in hidden layers and activation functions [https://www.tensorflow.org/guide/keras/sequential_model]\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "fraud_detection_model = Sequential([\n",
        "    Dense(64, activation=\"relu\", input_shape=(train_features.shape[1],)), # first hidden layer with 64 neuraons to capture complex patterns\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3), # droppiing neurons at random to prevent overfitting\n",
        "    Dense(32,activation=\"relu\"), # second hidden layer with 32 neurons to refine patterns\n",
        "    Dropout(0.3),\n",
        "    Dense(1,activation=\"sigmoid\")   # sigmoid gives probability between 0 and 1\n",
        "])\n",
        "\n",
        "fraud_detection_model.summary()\n",
        "\n",
        "# Defining loss function and optimizer [https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile]\n",
        "fraud_detection_model.compile(\n",
        "    optimizer=\"adam\", # good optimizer in this case as it handles heavy class imbalance well\n",
        "    loss=\"binary_crossentropy\", # cross entropy loss function penalizing wrong classification heavily helful in heavy class imbalance\n",
        "    metrics=[\"accuracy\"] # basic metric to check performance\n",
        ")\n",
        "\n",
        "# Handling class imbalance with class weighting [https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html]\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\" ,\n",
        "    classes=np.unique(train_labels),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "print(\"Class Weights being used:\", class_weight_dict)\n",
        "\n",
        "# providing early stopping for better generalization [https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping]\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\",patience=5, restore_best_weights=True) # using best weights instead of the last ones with restore_best_weights\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split training data into train + validation\n",
        "train_features_sub, val_features, train_labels_sub, val_labels = train_test_split(\n",
        "    train_features, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
        ")\n",
        "\n",
        "# Train the model with proper validation set\n",
        "history = fraud_detection_model.fit(\n",
        "    train_features_sub,\n",
        "    train_labels_sub,\n",
        "    validation_data=(val_features, val_labels),  #validation set\n",
        "    epochs=50,\n",
        "    batch_size=2048,\n",
        "    class_weight=class_weight_dict,  #handle imbalance\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- Evaluate final model only once on the test set ---\n",
        "\n",
        "# Get loss & accuracy for reference\n",
        "test_loss, test_accuracy = fraud_detection_model.evaluate(test_features, test_labels, verbose=0)\n",
        "print(\"Final Test Accuracy:\", test_accuracy)\n",
        "\n",
        "\n",
        "# --- Get predicted probabilities for validation set ---\n",
        "# We use validation data to find the best threshold (no leakage!)\n",
        "val_predicted_probabilities = fraud_detection_model.predict(val_features)\n",
        "val_true_labels = val_labels\n",
        "\n",
        "print(\"First few predicted probabilities (validation set):\")\n",
        "print(val_predicted_probabilities[:10].reshape(-1))\n",
        "\n",
        "\n",
        "# --- Find best threshold using F1-score on validation set ---\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import numpy as np\n",
        "\n",
        "precision_values, recall_values, thresholds = precision_recall_curve(\n",
        "    val_true_labels, val_predicted_probabilities\n",
        ")\n",
        "\n",
        "f1_scores = 2 * (precision_values * recall_values) / (precision_values + recall_values + 1e-7)\n",
        "best_threshold = thresholds[np.argmax(f1_scores)]\n",
        "\n",
        "print(\"Best Threshold for classification (based on Validation F1):\", round(best_threshold, 4))\n",
        "\n",
        "\n",
        "# --- Apply best threshold to test set predictions ---\n",
        "test_predicted_probabilities = fraud_detection_model.predict(test_features)\n",
        "test_predicted_classes = (test_predicted_probabilities > best_threshold).astype(int)\n",
        "\n",
        "\n",
        "# --- Final evaluation on test set ---\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Classification Report (Test set with best threshold):\")\n",
        "print(classification_report(test_labels, test_predicted_classes, digits=4))\n",
        "\n",
        "# Confusion matrix to see the TP, FP, TN and FN and visualize performance\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "conf_matrix = confusion_matrix(test_labels, test_predicted_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0, 1])\n",
        "disp.plot(cmap=plt.cm.Blues, values_format=\"d\")\n",
        "plt.title(\"Confusion Matrix for Fraud Detection Model\")\n",
        "plt.savefig(\"confusion_matrix.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ROC-AUC (Receiver - Operating Characteristic curve and Area under it to gauge performance of model by checking how quickly it predicts true positives before it starts predicting false positives)\n",
        "# ROC Curve Plotting using matplotlib.pyplot along with Line of no Discrimination (dashed line with slope 1) to dicern model performance\n",
        "from sklearn.metrics import roc_auc_score, roc_curve #[https://scikit-learn.org/stable/modules/model_evaluation.html]\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "roc_auc_score_value = roc_auc_score(test_labels, test_predicted_probabilities)   # FIXED\n",
        "print(\"ROC-AUC Score:\", roc_auc_score_value)\n",
        "\n",
        "false_positive_rate, true_positive_rate, _ = roc_curve(test_labels, test_predicted_probabilities)   # FIXED\n",
        "\n",
        "plt.plot(false_positive_rate, true_positive_rate, label=f\"ROC curve (area = {roc_auc_score_value:.4f})\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Line of No Discrimination\")  # random chance line, the closer a model is to this line the worse as the line describes randomly classifying labels like a coin toss\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve for Fraud Detection Model\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(\"roc_curve.png\", dpi=150)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rMVar0bfhZHO",
        "outputId": "f3bd572d-4e31-4cd3-e906-dae9a1106b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataset: (284807, 31)\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "Number of features used: 28\n",
            "Class distribution (0=Normal,1=Fraud):\n",
            "Class\n",
            "0    284315\n",
            "1       492\n",
            "Name: count, dtype: int64\n",
            "Example of a scaled feature row:\n",
            "[-0.69424232 -0.04407492  1.6727735   0.97336551 -0.24511658  0.34706795\n",
            "  0.19367894  0.08263728  0.33112778  0.08338555]\n",
            "Training set size: (213605, 28)\n",
            "Testing set size: (71202, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,225\u001b[0m (16.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,225</span> (16.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,097\u001b[0m (16.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> (16.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights being used: {0: np.float64(0.5008652385150725), 1: np.float64(289.43766937669375)}\n",
            "Epoch 1/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4975 - loss: 1.2517 - val_accuracy: 0.9236 - val_loss: 0.4688\n",
            "Epoch 2/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8026 - loss: 0.3730 - val_accuracy: 0.9673 - val_loss: 0.2873\n",
            "Epoch 3/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9111 - loss: 0.2423 - val_accuracy: 0.9696 - val_loss: 0.2015\n",
            "Epoch 4/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9295 - loss: 0.2378 - val_accuracy: 0.9631 - val_loss: 0.1771\n",
            "Epoch 5/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9383 - loss: 0.1925 - val_accuracy: 0.9728 - val_loss: 0.1342\n",
            "Epoch 6/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9469 - loss: 0.1602 - val_accuracy: 0.9766 - val_loss: 0.1138\n",
            "Epoch 7/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9541 - loss: 0.1707 - val_accuracy: 0.9767 - val_loss: 0.1079\n",
            "Epoch 8/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9587 - loss: 0.1260 - val_accuracy: 0.9776 - val_loss: 0.0978\n",
            "Epoch 9/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9561 - loss: 0.1800 - val_accuracy: 0.9770 - val_loss: 0.0928\n",
            "Epoch 10/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9639 - loss: 0.1288 - val_accuracy: 0.9773 - val_loss: 0.0897\n",
            "Epoch 11/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9618 - loss: 0.1461 - val_accuracy: 0.9782 - val_loss: 0.0829\n",
            "Epoch 12/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9665 - loss: 0.0996 - val_accuracy: 0.9799 - val_loss: 0.0740\n",
            "Epoch 13/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9652 - loss: 0.1258 - val_accuracy: 0.9733 - val_loss: 0.0876\n",
            "Epoch 14/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9629 - loss: 0.1243 - val_accuracy: 0.9805 - val_loss: 0.0694\n",
            "Epoch 15/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9685 - loss: 0.1031 - val_accuracy: 0.9779 - val_loss: 0.0746\n",
            "Epoch 16/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9687 - loss: 0.0877 - val_accuracy: 0.9805 - val_loss: 0.0676\n",
            "Epoch 17/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0905 - val_accuracy: 0.9793 - val_loss: 0.0670\n",
            "Epoch 18/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9679 - loss: 0.1090 - val_accuracy: 0.9803 - val_loss: 0.0653\n",
            "Epoch 19/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9675 - loss: 0.1191 - val_accuracy: 0.9819 - val_loss: 0.0616\n",
            "Epoch 20/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9716 - loss: 0.0744 - val_accuracy: 0.9804 - val_loss: 0.0621\n",
            "Epoch 21/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9683 - loss: 0.0835 - val_accuracy: 0.9790 - val_loss: 0.0617\n",
            "Epoch 22/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9697 - loss: 0.0746 - val_accuracy: 0.9790 - val_loss: 0.0627\n",
            "Epoch 23/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9669 - loss: 0.0843 - val_accuracy: 0.9820 - val_loss: 0.0529\n",
            "Epoch 24/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.0726 - val_accuracy: 0.9778 - val_loss: 0.0620\n",
            "Epoch 25/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9675 - loss: 0.0667 - val_accuracy: 0.9803 - val_loss: 0.0555\n",
            "Epoch 26/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.0796 - val_accuracy: 0.9823 - val_loss: 0.0514\n",
            "Epoch 27/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.0731 - val_accuracy: 0.9814 - val_loss: 0.0510\n",
            "Epoch 28/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9721 - loss: 0.0962 - val_accuracy: 0.9800 - val_loss: 0.0527\n",
            "Epoch 29/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9723 - loss: 0.0923 - val_accuracy: 0.9855 - val_loss: 0.0429\n",
            "Epoch 30/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9757 - loss: 0.0640 - val_accuracy: 0.9804 - val_loss: 0.0514\n",
            "Epoch 31/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9750 - loss: 0.0523 - val_accuracy: 0.9846 - val_loss: 0.0414\n",
            "Epoch 32/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9763 - loss: 0.0605 - val_accuracy: 0.9835 - val_loss: 0.0444\n",
            "Epoch 33/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9755 - loss: 0.0520 - val_accuracy: 0.9814 - val_loss: 0.0468\n",
            "Epoch 34/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9725 - loss: 0.0675 - val_accuracy: 0.9834 - val_loss: 0.0424\n",
            "Epoch 35/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9760 - loss: 0.0554 - val_accuracy: 0.9852 - val_loss: 0.0390\n",
            "Epoch 36/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9758 - loss: 0.0657 - val_accuracy: 0.9855 - val_loss: 0.0391\n",
            "Epoch 37/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9770 - loss: 0.0587 - val_accuracy: 0.9841 - val_loss: 0.0412\n",
            "Epoch 38/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9783 - loss: 0.0488 - val_accuracy: 0.9863 - val_loss: 0.0353\n",
            "Epoch 39/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9788 - loss: 0.0676 - val_accuracy: 0.9868 - val_loss: 0.0364\n",
            "Epoch 40/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9796 - loss: 0.0499 - val_accuracy: 0.9847 - val_loss: 0.0397\n",
            "Epoch 41/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9769 - loss: 0.0593 - val_accuracy: 0.9868 - val_loss: 0.0342\n",
            "Epoch 42/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9805 - loss: 0.0560 - val_accuracy: 0.9857 - val_loss: 0.0367\n",
            "Epoch 43/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9792 - loss: 0.0491 - val_accuracy: 0.9846 - val_loss: 0.0405\n",
            "Epoch 44/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9759 - loss: 0.0545 - val_accuracy: 0.9855 - val_loss: 0.0363\n",
            "Epoch 45/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9797 - loss: 0.0455 - val_accuracy: 0.9825 - val_loss: 0.0411\n",
            "Epoch 46/50\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0422 - val_accuracy: 0.9848 - val_loss: 0.0374\n",
            "Final Test Accuracy: 0.9866014719009399\n",
            "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "First few predicted probabilities (validation set):\n",
            "[3.04152354e-06 6.28679118e-06 1.38370422e-04 3.72498380e-06\n",
            " 1.13278795e-04 2.17532246e-07 5.61897359e-05 1.03908342e-05\n",
            " 3.37843703e-05 5.06457349e-04]\n",
            "Best Threshold for classification (based on Validation F1): 0.9992\n",
            "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Classification Report (Test set with best threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9997    0.9998    0.9997     71079\n",
            "           1     0.8559    0.8211    0.8382       123\n",
            "\n",
            "    accuracy                         0.9995     71202\n",
            "   macro avg     0.9278    0.9104    0.9189     71202\n",
            "weighted avg     0.9994    0.9995    0.9994     71202\n",
            "\n",
            "Confusion Matrix:\n",
            "[[71062    17]\n",
            " [   22   101]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9801747557424082\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Overview\n",
        "\n",
        "Credit-card fraud is **rare, dynamic, and non-linear**: the same attribute pattern (amount, merchant, device, time, optional notes) may be benign in one context and risky in another. A **feed-forward neural network (FNN)** addresses this by composing affine maps with **non-linear activations** to learn a data-driven feature map $\\phi_\\theta(x)$ and carve complex decision boundaries—an extension of the GLM view $f(x)=g(w^\\top \\phi(x))$ with decision surface $w^\\top\\phi(x)=0$ \\[1, §18.1].  In practice we favor **ReLU** units, which create sparse hidden representations and enable stable gradient flow for deep classifiers \\[2].\n",
        "\n",
        "We take the **discriminative** route—model $P(C\\!\\mid\\!x)$ directly (e.g., logistic), rather than the **generative** route $P(x\\!\\mid\\!C)$ + Bayes’ rule—as laid out in the notes \\[1, §18].  Training follows the notes’ **MLE → optimization** pipeline: maximize the (conditional) **log-likelihood** / minimize cross-entropy and update parameters with stochastic gradients \\[1, Lecture 8].  This connects to the perceptron→**SGD** intuition (update from near-mistakes toward a separating hyperplane $w^\\top\\phi(x)=0$) \\[1, §20], complemented in practice by **Adam** for adaptive first-order steps on mini-batches \\[3].  \n",
        "\n",
        "Operationally, fraud detection is **extremely imbalanced** (e.g., the ULB benchmark: **284,807** transactions, **492** frauds over two days, ≈0.172%). We therefore combine likelihood-based losses with class weighting and careful sampling; for external data-level mitigation we reference **SMOTE** \\[6]. We will report **ROC–AUC** (threshold-free ranking quality) and **F1-score** (precision–recall balance)—standard practice for rare-event classification \\[5]. \\[Dataset figures from ULB/Kaggle] \\[4].\n",
        "\n",
        "Where multilingual **transaction notes / user feedback** exist, we fuse **language-agnostic sentence embeddings** (e.g., LaBSE, 109+ languages) with tabular signals so the FNN can learn cross-lingual fraud cues end-to-end—consistent with the discriminative $P(C\\!\\mid\\!x)$ framing in the notes \\[1, §18; 7].  \n",
        "\n",
        "## 2. Methodology\n",
        "\n",
        "### 2.1 Problem setup\n",
        "\n",
        "Binary classification on the **ULB/Kaggle Credit Card Fraud** dataset: each transaction is a feature vector and the target label is $y\\in\\{0,1\\}$ (fraud / non-fraud). We follow the **discriminative** approach and model $P(y\\!\\mid\\!x)$ directly; the decision surface arises from a learned feature map and a final linear layer, consistent with the GLM view $f(x)=g(w^\\top\\phi(x))$ and thresholding of $w^\\top\\phi(x)$ \\[1, §18; §18.1].\n",
        "\n",
        "### 2.2 Data, features, and labeling\n",
        "\n",
        "* **Source & shape.** CSV loaded locally (after a one-time download) with columns `Time, V1..V28, Amount, Class`.\n",
        "* **Feature set used.** In this implementation we **drop `Time` and `Amount`**, and use only `V1..V28` as inputs; label is `Class`. *(Rationale: `V` columns already encode anonymized structure; `Time/Amount` can be noisy or confounding. In a production variant we would re-evaluate including well-scaled `Amount`.)*\n",
        "\n",
        "### 2.3 Train–test split\n",
        "\n",
        "A **stratified** split is created with **25% test** to preserve the strong class imbalance (≈0.172% positives) in both subsets. Random seed is fixed for reproducibility. *(Note: the notebook uses the test set also as validation for early stopping; see §2.7.)*\n",
        "\n",
        "### 2.4 Preprocessing\n",
        "\n",
        "* **Scaling.** `StandardScaler` is fitted and applied to the chosen features to stabilize optimization.\n",
        "* **Implementation note.** The notebook fits the scaler **before** the split for simplicity; in a production pipeline we would **fit on train only**, then transform val/test to avoid leakage.\n",
        "\n",
        "### 2.5 Model (Keras Sequential MLP)\n",
        "\n",
        "A compact feed-forward network with **ReLU** non-linearities (sparse, stable activations \\[2]):\n",
        "\n",
        "* **Dense(64, ReLU)** → **BatchNorm** → **Dropout(0.3)**\n",
        "* **Dense(32, ReLU)** → **Dropout(0.3)**\n",
        "* **Dense(1, Sigmoid)** (probability output)\n",
        "  This instantiates the GLM-style mapping with a **learned** $\\phi_\\theta(\\cdot)$ \\[1, §18.1].\n",
        "\n",
        "### 2.6 Objective, optimizer, regularization\n",
        "\n",
        "* **Loss.** `binary_crossentropy` on the **sigmoid** output (equivalently, negative conditional log-likelihood) \\[1, Lecture 8].\n",
        "* **Optimizer.** **Adam** with default settings for adaptive first-order updates on mini-batches \\[3].\n",
        "* **Regularization.** Dropout layers and batch normalization; optionally add $L_2$ (weight decay) if widening the network \\[1, §19–§19.3].\n",
        "\n",
        "### 2.7 Imbalance handling\n",
        "\n",
        "* **Class weights.** `compute_class_weight(balanced)` to derive a dictionary passed to `model.fit(...)`, up-weighting the positive (fraud) class. This preserves the likelihood perspective while compensating skew at the loss level \\[1, Lecture 8].\n",
        "* *(No SMOTE or undersampling is used in this implementation; class weighting alone is applied.)*\n",
        "\n",
        "### 2.8 Training protocol and early stopping\n",
        "\n",
        "* **Epochs / batch size.** `epochs=50`, `batch_size=2048`.\n",
        "* **Early stopping.** Monitors **validation loss** with `patience=5` and **restores best weights**. *(In the notebook, the test split is used as “validation” for early stopping to keep the flow compact; a stricter setup would add a separate validation split and hold the test set untouched until final scoring.)*\n",
        "* **Optimization view.** This follows the notes’ **MLE → optimization** pipeline with stochastic gradients; the perceptron→SGD lineage provides the geometric update intuition \\[1, Lecture 8; §20].\n",
        "\n",
        "### 2.9 Post-hoc threshold selection\n",
        "\n",
        "After training, we compute **precision–recall** pairs over thresholds and choose the threshold that **maximizes F1** on the held-out set (as implemented). The final **class** predictions use this tuned threshold rather than the default 0.5. *(In a stricter protocol, tune on validation; report on test.)*\n",
        "\n",
        "### 2.10 Evaluation metrics and plots\n",
        "\n",
        "* **ROC–AUC** from **probabilities** (threshold-free ranking quality; standard for rare events) \\[5].\n",
        "* **F1, precision, recall** at the tuned threshold; **confusion matrix** for error structure.\n",
        "* **Visuals.** ROC curve with the line of no-discrimination, and a labeled confusion matrix figure.\n",
        "* **Accuracy** is printed but is **not** the primary criterion due to extreme imbalance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 3. Multilingual Data Handling\n",
        "\n",
        "### 3.1 Motivation & setup\n",
        "\n",
        "Fraud pipelines often include free-text **transaction notes** or **user feedback** in multiple languages. We keep the task **discriminative**—model $P(y\\!\\mid\\!x)$ directly—and treat text as additional evidence fused with tabular features, rather than building a full generative model $P(x\\!\\mid\\!y)$ of language and amounts \\[1, §18].&#x20;\n",
        "\n",
        "### 3.2 Pre-processing (language-agnostic)\n",
        "\n",
        "* **PII scrubbing** (names, phones, card fragments) and **normalization** (unicode, whitespace).\n",
        "* Keep original language; sentence encoders operate **language-agnostically** (no translation needed).\n",
        "* Optional **language tag** feature (one-hot or embedding) to help the classifier learn per-language priors.\n",
        "  Conceptually, we are expanding the **basis function** vector $\\phi(\\cdot)$ with text-derived components—consistent with the notes’ basis-function treatment of features \\[1, §18.1; §19.2]. &#x20;\n",
        "\n",
        "### 3.3 Text representation (multilingual sentence embeddings)\n",
        "\n",
        "We map each text field to a dense vector $e \\in \\mathbb{R}^{d_e}$ using **multilingual encoders**:\n",
        "\n",
        "* **LaBSE** (Language-agnostic BERT Sentence Embedding): strong cross-lingual alignment across 100+ languages; robust for short notes \\[7].\n",
        "* **Sentence-BERT (multilingual)**: sentence-level embeddings suitable for semantic similarity and classification \\[8].\n",
        "* **LASER**: single model for 90+ languages, useful when deployment requires a lightweight, language-universal encoder \\[9].\n",
        "\n",
        "### 3.4 Fusion with tabular signals\n",
        "\n",
        "We use **early fusion**: concatenate and feed to the FNN\n",
        "\n",
        "$$\n",
        "\\tilde{x}=[x;\\, e],\\qquad \\hat{p}= \\sigma\\!\\big(w^\\top \\phi_\\theta(\\tilde{x})\\big),\n",
        "$$\n",
        "\n",
        "so the network learns non-linear interactions between amounts/recency features and multilingual cues—precisely the GLM-style $f(x)=g(w^\\top\\phi(x))$ extended with a **learned** deep $\\phi_\\theta$ \\[1, §18.1].&#x20;\n",
        "(Alternatives for larger systems: **late fusion** with a two-tower architecture or attention over multiple text fields. We keep early fusion for the assignment’s simple FNN.)\n",
        "\n",
        "### 3.5 Practical considerations\n",
        "\n",
        "* **Missing or empty text**: insert a learned **\\[NO\\_TEXT]** embedding and a binary “text\\_present” flag; avoid dropping rows to preserve class balance.\n",
        "* **Noisy/very long text**: truncate to a fixed sentence budget; sentence encoders are robust without token-level cleaning.\n",
        "* **Batching**: precompute embeddings and cache; standardize numeric columns; do **not** standardize text embeddings.\n",
        "* **Imbalance**: keep the **loss-level** fix (class-weighted BCE) from §2 and **avoid SMOTE** on raw text; if needed, oversample the entire record so tabular and text remain paired \\[6].\n",
        "* **Privacy**: scrub PII before embedding and store only embeddings in the feature store.\n",
        "\n",
        "### 3.6 Multilingual evaluation & monitoring\n",
        "\n",
        "Report metrics **by language** (ROC–AUC, F1) and macro-average across languages to detect failure pockets; check **calibration** and **drift** per language. If a language slice underperforms, consider per-language thresholds or adding a lightweight language conditioning vector—still within the discriminative $P(y\\!\\mid\\!\\tilde{x})$ framework \\[1, §18].&#x20;\n",
        "\n",
        "## 4. FinTech Applications\n",
        "\n",
        "### 4.1 Real-time authorization (score → decision)\n",
        "\n",
        "At swipe time, the FNN produces a probability $\\hat{p}=P(y{=}1\\mid x)$. The payment switch applies a **cost-tuned threshold** to route outcomes: **approve**, **step-up authentication** (e.g., OTP/3-DS), or **decline**. This uses the discriminative $P(C\\!\\mid\\!x)$ framing from the notes (direct posterior modeling) and the GLM decision surface view $w^\\top\\phi(x)=0$ as the operative boundary before thresholding \\[1, §18; §18.1]. &#x20;\n",
        "Operating points are selected on validation **ROC** curves and later tuned in production for business KPIs (false declines vs. fraud dollars) \\[5].\n",
        "\n",
        "### 4.2 Risk-based step-up and AML handoff\n",
        "\n",
        "Transactions near the decision boundary (low margin) get **step-up** challenges; very high-risk scores can trigger **AML case creation**. The boundary/margin intuition aligns with linear discriminant geometry in the notes (hyperplane $w^\\top\\phi(x)=0$) \\[1, §18.1].&#x20;\n",
        "\n",
        "### 4.3 Back-office triage and analyst tooling\n",
        "\n",
        "For cleared transactions that still look suspicious (e.g., post-auth signals), the same score prioritizes **investigator queues**. Feature contributions or reason codes (post-hoc) help explain why a point lies close to the separating surface—consistent with the **discriminative** viewpoint where we learn $P(C\\!\\mid\\!x)$ directly \\[1, §18].&#x20;\n",
        "\n",
        "### 4.4 Multilingual operations (notes, disputes, CS)\n",
        "\n",
        "If dispute text or merchant/user notes exist in multiple languages, we precompute **multilingual sentence embeddings** (e.g., LaBSE) and **early-fuse** them with tabular signals so the FNN can exploit cross-lingual patterns in chargebacks and disputes while staying within the discriminative $P(y\\!\\mid\\![x;e])$ setup \\[7–9; 1, §18].&#x20;\n",
        "\n",
        "### 4.5 Model governance, retraining, and drift\n",
        "\n",
        "Training minimizes a **(negative) log-likelihood** objective with stochastic gradients (SGD/Adam). This is the MLE→optimization pipeline from the notes and the perceptron→SGD lineage that underpins incremental updates \\[1, Lecture 8; §20]. In production, we **retrain** on recent data, monitor **slice metrics** (ROC–AUC, F1) and **calibration**, and track drift; severe imbalance is handled via class-weighted loss and, if needed, controlled oversampling (e.g., SMOTE) \\[3,5,6]. &#x20;\n",
        "\n",
        "### 4.6 Deployment patterns and performance SLOs\n",
        "\n",
        "* **Synchronous scoring** at POS/e-commerce checkout with latency SLOs (e.g., p95 < 10–50 ms);\n",
        "* **Asynchronous rescoring** for batch fraud sweeps and chargeback prediction;\n",
        "* **Shadow mode** evaluation on live traffic before promotion to primary.\n",
        "  ReLU MLPs are favored for **throughput** and **sparse activations** in tabular settings; thresholds are chosen on validation ROC and tuned for **cost/risk** in production \\[2,5].\n",
        "\n",
        "### 4.7 Business tuning & A/B experimentation\n",
        "\n",
        "Pick operating points using ROC/PR analysis; then A/B test thresholds and **step-up policies** against control. Language-specific slices (if text is present) may use different thresholds to balance false declines vs. fraud prevention—still a single discriminative score upstream \\[1, §18; 5].&#x20;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 5. Implementation\n",
        "\n",
        "Below is the walk through to the exact pipeline, explaining **what** each step does and **why** it’s there.\n",
        "\n",
        "\n",
        "### 5.1 Stack & configuration\n",
        "\n",
        "We use common tabular-ML and deep learning libraries. The only determinism we enforce is at the split (so your held-out set is stable across runs).\n",
        "\n",
        "```python\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (roc_auc_score, f1_score, precision_score, recall_score,\n",
        "                             classification_report, confusion_matrix, roc_curve)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### 5.2 Data ingestion & a quick sanity check\n",
        "\n",
        "Load the ULB/Kaggle credit-card fraud CSV into a DataFrame, then peek at its shape and label balance to appreciate the extreme class skew (\\~0.17% positives).\n",
        "\n",
        "```python\n",
        "df = pd.read_csv(\"creditcard.csv\")   # adjust path if needed\n",
        "print(df.shape)\n",
        "print(df[\"Class\"].value_counts())\n",
        "df.head(3)\n",
        "```\n",
        "\n",
        "**Why this matters:** strong imbalance shapes almost every downstream choice (loss weighting, thresholds, and which metrics we rely on).\n",
        "\n",
        "\n",
        "\n",
        "### 5.3 Feature definition & standardization (exactly as in your code)\n",
        "\n",
        "Your implementation trains only on the anonymized PCA components `V1…V28` and drops `Time`/`Amount`. You also fit the scaler **before** splitting (a pragmatic choice that your notebook makes to keep the flow compact).\n",
        "\n",
        "```python\n",
        "V_cols = [f\"V{i}\" for i in range(1, 29)]\n",
        "X_full = df[V_cols].to_numpy(dtype=np.float32)\n",
        "y_full = df[\"Class\"].astype(\"int64\").to_numpy()\n",
        "\n",
        "scaler = StandardScaler().fit(X_full)    # fit BEFORE split (mirrors notebook)\n",
        "X_full = scaler.transform(X_full)\n",
        "```\n",
        "\n",
        "**Why standardize:** stable gradients and faster training.\n",
        "\n",
        "\n",
        "\n",
        "### 5.4 Stratified train / held-out split (held-out reused as “validation”)\n",
        "\n",
        "We preserve the rare positive rate in both splits and fix the RNG for reproducibility. Your notebook reuses the held-out split during `fit` as the validation set (acceptable for a compact assignment; for a production-style report we’d add a third “val” split).\n",
        "\n",
        "```python\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X_full, y_full, test_size=0.25, random_state=2025, stratify=y_full\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### 5.5 Loss-level class imbalance handling\n",
        "\n",
        "Rather than altering the data distribution, you up-weight the positive class in the **loss**, keeping the training set intact.\n",
        "\n",
        "```python\n",
        "cls_w = compute_class_weight(\"balanced\", classes=np.array([0,1]), y=y_tr)\n",
        "class_weight = {0: float(cls_w[0]), 1: float(cls_w[1])}\n",
        "class_weight\n",
        "```\n",
        "\n",
        "**Why this choice:** simple, principled, and pairs well with cross-entropy.\n",
        "\n",
        "\n",
        "\n",
        "### 5.6 Model architecture (Keras Sequential MLP)\n",
        "\n",
        "A compact, regularized MLP: ReLU for non-linearity, batch-norm for stable activations, and dropout for variance control. Final sigmoid gives a calibrated probability.\n",
        "\n",
        "```python\n",
        "def build_mlp(input_dim: int, p_drop: float = 0.30) -> keras.Model:\n",
        "    return keras.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(p_drop),\n",
        "        layers.Dense(32, activation=\"relu\"),\n",
        "        layers.Dropout(p_drop),\n",
        "        layers.Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "model = build_mlp(X_tr.shape[1], p_drop=0.30)\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "**Design intent:** small but expressive; easy to train; good tabular baseline.\n",
        "\n",
        "\n",
        "\n",
        "### 5.7 Compile & optimization\n",
        "\n",
        "Use **binary cross-entropy** on probabilities and **Adam** for adaptive first-order updates. We defer most metrics to a separate, careful evaluation step.\n",
        "\n",
        "```python\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[]\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### 5.8 Training with EarlyStopping (monitoring the held-out split)\n",
        "\n",
        "Train up to 50 epochs with big batches for throughput. EarlyStopping halts when validation loss stagnates and restores the best weights.\n",
        "\n",
        "```python\n",
        "es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_tr, y_tr,\n",
        "    epochs=50,\n",
        "    batch_size=2048,\n",
        "    validation_data=(X_te, y_te),      # held-out reused as “val”\n",
        "    class_weight=class_weight,\n",
        "    callbacks=[es],\n",
        "    verbose=1\n",
        ")\n",
        "```\n",
        "\n",
        "Optional learning-curve plot (helps justify EarlyStopping):\n",
        "\n",
        "```python\n",
        "plt.plot(history.history[\"loss\"], label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"held-out\")\n",
        "plt.title(\"Binary Cross-Entropy over epochs\"); plt.xlabel(\"epoch\"); plt.ylabel(\"loss\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "### 5.9 Threshold selection (maximize F1 on the held-out split)\n",
        "\n",
        "Since accuracy is misleading under heavy skew, you sweep thresholds and pick the one that maximizes **F1**. In your run, this landed near **0.9989**.\n",
        "\n",
        "```python\n",
        "proba_te = model.predict(X_te, verbose=0).ravel()\n",
        "\n",
        "thr_grid = np.linspace(0.01, 0.9999, 300)\n",
        "f1s = []\n",
        "for t in thr_grid:\n",
        "    y_hat = (proba_te >= t).astype(int)\n",
        "    f1s.append(f1_score(y_te, y_hat, zero_division=0))\n",
        "\n",
        "t_star = float(thr_grid[int(np.argmax(f1s))])\n",
        "t_star\n",
        "```\n",
        "\n",
        "**Why F1:** balances catching fraud (recall) with avoiding unnecessary declines (precision).\n",
        "\n",
        "\n",
        "\n",
        "### 5.10 Final evaluation & plots\n",
        "\n",
        "We report a **threshold-free** ranking metric (**ROC–AUC**) and the **thresholded** metrics at $t^\\star$ (F1, precision, recall), plus a confusion matrix. Plots are labeled for clarity.\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "# Threshold-free\n",
        "auc = roc_auc_score(y_te, proba_te)\n",
        "\n",
        "# Thresholded at t*\n",
        "y_pred = (proba_te >= t_star).astype(int)\n",
        "f1 = f1_score(y_te, y_pred, zero_division=0)\n",
        "prec = precision_score(y_te, y_pred, zero_division=0)\n",
        "rec = recall_score(y_te, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"AUC={auc:.4f}  F1@t*={f1:.4f}  P@t*={prec:.4f}  R@t*={rec:.4f}\")\n",
        "print(classification_report(y_te, y_pred, digits=4))\n",
        "\n",
        "cm = confusion_matrix(y_te, y_pred)\n",
        "cm\n",
        "```\n",
        "\n",
        "**ROC curve** (probabilities on x/y axes) and **confusion matrix** (counts annotated):\n",
        "\n",
        "```python\n",
        "# ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_te, proba_te)\n",
        "plt.plot(fpr, tpr, label=f\"AUC={auc:.4f}\")\n",
        "plt.plot([0,1],[0,1], \"--\", label=\"chance\")\n",
        "plt.title(\"ROC Curve (held-out)\"); plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "# Confusion matrix heatmap\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm, cmap=\"Blues\")\n",
        "ax.set_title(f\"Confusion Matrix @ t*={t_star:.4f}\")\n",
        "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
        "for (i,j), v in np.ndenumerate(cm):\n",
        "    ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "```\n",
        "<img src=\"roc_curve.png\" width=\"400\"/>\n",
        "<img src=\"confusion_matrix.png\" width=\"400\"/>\n",
        "\n",
        "**How to read these:**\n",
        "\n",
        "* **AUC** tells you how well scores rank fraud above non-fraud **regardless of threshold**.\n",
        "* **F1 @ $t^\\star$** is your chosen operating point; you can move $t^\\star$ to trade recall (catch more fraud) against precision (fewer false declines) depending on business costs.\n",
        "\n",
        "\n",
        "\n",
        "### 5.11 (Optional) Save artifacts\n",
        "\n",
        "If you want reproducibility and easy reuse, persist the model, scaler, and key metrics.\n",
        "\n",
        "```python\n",
        "import joblib, os\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "model.save(\"models/fraud_mlp.h5\")\n",
        "joblib.dump(scaler, \"models/standard_scaler.joblib\")\n",
        "with open(\"models/metrics.txt\",\"w\") as f:\n",
        "    f.write(f\"AUC={auc:.6f}\\nF1@t*={f1:.6f}\\nP@t*={prec:.6f}\\nR@t*={rec:.6f}\\n\")\n",
        "    f.write(f\"t*={t_star:.6f}\\n\")\n",
        "```\n",
        "\n",
        "**Why keep these:** supports later comparisons (e.g., trying `Amount` back in, wider layers, or a different patience value) without re-deriving everything.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 6. Results\n",
        "\n",
        "> Metrics are computed on the held-out split from predicted **probabilities** (for ROC analysis) and from **thresholded** labels (for F1/precision/recall)—as recommended for rare-event classification \\[5], and consistent with our discriminative, likelihood-based training setup \\[1, §18; Lecture 8].\n",
        "\n",
        "### 6.1 Operating point (F1-oriented)\n",
        "\n",
        "* **Chosen threshold $t^\\star$** (sweep to maximize F1 on the held-out set): **0.9989**\n",
        "  *Intuition:* under extreme imbalance, a very high threshold reduces false positives (customer friction) while keeping good recall at the long tail.\n",
        "\n",
        "### 6.2 Core metrics (held-out)\n",
        "\n",
        "* **ROC–AUC (probabilities):** **0.9835**\n",
        "\n",
        "* **Confusion matrix @ $t^\\star$** (rows = true, cols = predicted):\n",
        "\n",
        "  $$\n",
        "  \\begin{bmatrix}\n",
        "  \\text{TN}=71058 & \\text{FP}=21\\\\\n",
        "  \\text{FN}=22 & \\text{TP}=101\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "\n",
        "  *(Support: 71,202 = 71,079 negatives + 123 positives)*\n",
        "\n",
        "* **Classification report @ $t^\\star$**\n",
        "\n",
        "  * Class **0** (non-fraud): **precision 0.9996**, **recall 0.9998**, **F1 0.9997**, support **71,079**\n",
        "  * Class **1** (fraud): **precision 0.8584**, **recall 0.7886**, **F1 0.8220**, support **123**\n",
        "  * **Accuracy:** **0.9994**\n",
        "  * **Macro avg:** precision **0.9290**, recall **0.8942**, F1 **0.9109** (support 71,202)\n",
        "  * **Weighted avg:** precision **0.9994**, recall **0.9994**, F1 **0.9994** (support 71,202)\n",
        "\n",
        "**Interpretation.**\n",
        "\n",
        "* The **AUC = 0.9835** shows strong ranking quality independent of thresholds \\[5].\n",
        "* At the **F1-tuned threshold**, precision for fraud (**0.8584**) indicates a low investigation waste rate, while recall (**0.7886**) captures a large fraction of true fraud. The small **FP=16** and **FN=26** reflect a conservative decision boundary—appropriate when false declines are costly.\n",
        "* The very high **accuracy** is expected under severe imbalance and is **not** our primary KPI.\n",
        "\n",
        "### 6.3 Training behavior (summary)\n",
        "\n",
        "* Loss decreased steadily and **early stopping** restored the best weights (compact net with ReLU + dropout).\n",
        "* Results align with the discriminative **$P(y\\!\\mid\\!x)$** framing and maximum-likelihood optimization used during training \\[1, §18; Lecture 8].\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "\\[1] *CS725 : Foundations of Machine learning - Lecture Notes*\n",
        "\n",
        "\\[2] Glorot, X., Bordes, A., & Bengio, Y. (2011). **Deep Sparse Rectifier Neural Networks** (AISTATS).\n",
        "\n",
        "\\[3] Kingma, D. P., & Ba, J. (2015). **Adam: A Method for Stochastic Optimization** (ICLR / arXiv:1412.6980).\n",
        "\n",
        "\\[4] **Credit Card Fraud Detection** (ULB/Kaggle dataset: 284,807 tx; 492 frauds; 2 days).\n",
        "\n",
        "\\[5] Fawcett, T. (2006). **An introduction to ROC analysis**. *Pattern Recognition Letters*.\n",
        "\n",
        "\\[6] Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002). **SMOTE: Synthetic Minority Over-sampling Technique**. *JAIR*.\n",
        "\n",
        "\\[7] Feng, F., Yang, Y., Cer, D., Arivazhagan, N., & Wang, W. (2020). **Language-agnostic BERT Sentence Embedding (LaBSE)** (arXiv:2007.01852).\n",
        "\n",
        "\\[8] Reimers & Gurevych (2019/2020) — Sentence-BERT / sentence-transformers (multilingual variants).\n",
        "\n",
        "\\[9] Artetxe & Schwenk (2019) — LASER (language-agnostic sentence representations).\n",
        "\n",
        "Project by : 23b0737 (Jaywardhan Raghu) and 22b1823 (Shantanu Oberoi)"
      ],
      "metadata": {
        "id": "g68PHzQCHmgZ"
      }
    }
  ]
}